{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import misc, spatial\n",
    "from math import log, exp, pow\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import cv2\n",
    "from math import sqrt\n",
    "from scipy.cluster.vq import vq\n",
    "import scipy.misc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(image_a, image_b):\n",
    "    # calculate mean square error between two images\n",
    "    err = np.sum((image_a.astype(float) - image_b.astype(float)) ** 2)\n",
    "    err /= float(image_a.shape[0] * image_a.shape[1])\n",
    "\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM(object):\n",
    "\n",
    "    def __init__(self, rows, columns, dimensions, epochs, number_of_input_vectors, alpha, sigma):\n",
    "\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        self.dimensions = dimensions\n",
    "        self.epochs = epochs\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        self.number_of_input_vectors = number_of_input_vectors\n",
    "        self.number_of_iterations = self.epochs * self.number_of_input_vectors\n",
    "\n",
    "        self.weight_vectors = np.random.uniform(0, 255, (self.rows * self.columns, self.dimensions))\n",
    "\n",
    "    def get_bmu_location(self, input_vector, weights):\n",
    "\n",
    "        tree = spatial.KDTree(weights)\n",
    "        bmu_index = tree.query(input_vector)[1]\n",
    "        return np.array([int(bmu_index/self.columns), bmu_index % self.columns])\n",
    "\n",
    "    def update_weights(self, iter_no, bmu_location, input_data):\n",
    "\n",
    "        learning_rate_op = 1 - (iter_no/float(self.number_of_iterations))\n",
    "        alpha_op = self.alpha * learning_rate_op\n",
    "        sigma_op = self.sigma * learning_rate_op\n",
    "\n",
    "        distance_from_bmu = []\n",
    "        for x in range(self.rows):\n",
    "            for y in range(self.columns):\n",
    "                distance_from_bmu = np.append(distance_from_bmu, np.linalg.norm(bmu_location - np.array([x, y])))\n",
    "\n",
    "        neighbourhood_function = [exp(-0.5 * pow(val, 2) / float(pow(sigma_op, 2))) for val in distance_from_bmu]\n",
    "\n",
    "        final_learning_rate = [alpha_op * val for val in neighbourhood_function]\n",
    "\n",
    "        for l in range(self.rows * self.columns):\n",
    "            weight_delta = [val*final_learning_rate[l] for val in (input_data - self.weight_vectors[l])]\n",
    "            updated_weight = self.weight_vectors[l] + np.array(weight_delta)\n",
    "            self.weight_vectors[l] = updated_weight\n",
    "\n",
    "    def train(self, input_data):\n",
    "\n",
    "        iter_no = 0\n",
    "        for epoch_number in range(self.epochs):\n",
    "            for index, input_vector in enumerate(input_data):\n",
    "                bmu_location = self.get_bmu_location(input_vector, self.weight_vectors)\n",
    "                self.update_weights(iter_no, bmu_location, input_vector)\n",
    "                iter_no += 1\n",
    "        return self.weight_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source image\n",
    "image_location = \"data/Lenna.png\"\n",
    "image = cv2.imread(image_location, cv2.IMREAD_GRAYSCALE)\n",
    "image_height = len(image)\n",
    "image_width = len(image[0])\n",
    "image_height, image_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error =  252.11402893066406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "# dimension of the vector\n",
    "block_width = 4\n",
    "block_height = 4\n",
    "vector_dimension = block_width*block_height\n",
    "\n",
    "# size of the codebook. For e.g., for a 256-vector codebook, this value should be 8 as 2^8 = 256\n",
    "bits_per_codevector = 2  # range [1,10]\n",
    "codebook_size = pow(2, bits_per_codevector)\n",
    "\n",
    "epochs = 5 # number of iterations\n",
    "\n",
    "initial_learning_rate = 0.7\n",
    "\n",
    "# dividing the image into 4*4 blocks of pixels\n",
    "image_vectors = []\n",
    "for i in range(0, image_height, block_height):\n",
    "    for j in range(0, image_width, block_width):\n",
    "        image_vectors.append(np.reshape(image[i:i+block_width, j:j+block_height], vector_dimension))\n",
    "image_vectors = np.asarray(image_vectors).astype(float)\n",
    "number_of_image_vectors = image_vectors.shape[0]\n",
    "\n",
    "# properties of the SOM grid\n",
    "som_rows = int(pow(2, int((log(codebook_size, 2))/2)))\n",
    "som_columns = int(codebook_size/som_rows)\n",
    "\n",
    "som = SOM(som_rows, som_columns, vector_dimension, epochs, number_of_image_vectors,\n",
    "          initial_learning_rate, max(som_rows, som_columns)/2)\n",
    "reconstruction_values = som.train(image_vectors)\n",
    "\n",
    "image_vector_indices, distance = vq(image_vectors, reconstruction_values)\n",
    "\n",
    "image_after_compression = np.zeros([image_width, image_height], dtype=\"uint8\")\n",
    "for index, image_vector in enumerate(image_vectors):\n",
    "    start_row = int(index / (image_width/block_width)) * block_height\n",
    "    end_row = start_row + block_height\n",
    "    start_column = (index*block_width) % image_width\n",
    "    end_column = start_column + block_width\n",
    "    image_after_compression[start_row:end_row, start_column:end_column] = \\\n",
    "        np.reshape(reconstruction_values[image_vector_indices[index]],\n",
    "                   (block_width, block_height))\n",
    "\n",
    "output_image_name = \"CB_size=\" + str(codebook_size) + \".png\"\n",
    "scipy.misc.imsave(output_image_name, image_after_compression)\n",
    "\n",
    "print(\"Mean Square Error = \", mse(image, image_after_compression) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
